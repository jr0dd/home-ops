---
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: thanos-query
  namespace: monitoring
spec:
  groups:
    - name: thanos-query
      rules:
        - alert: ThanosQueryIsDown
          annotations:
            description: ThanosQuery has disappeared. Prometheus target for the component
              cannot be discovered.
            runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosqueryisdown
            summary: Thanos component has disappeared.
          expr: |
            absent(up{job=~".*thanos-query.*"} == 1)
          for: 5m
          labels:
            severity: critical
        - alert: ThanosQueryHttpRequestQueryErrorRateHigh
          annotations:
            description: Thanos Query {{$labels.job}} is failing to handle {{$value | humanize}}%
              of "query" requests.
            runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosqueryhttprequestqueryerrorratehigh
            summary: Thanos Query is failing to handle requests.
          expr: |
            (
              sum by (job) (rate(http_requests_total{code=~"5..", job=~".*thanos-query.*", handler="query"}[5m]))
            /
              sum by (job) (rate(http_requests_total{job=~".*thanos-query.*", handler="query"}[5m]))
            ) * 100 > 5
          for: 5m
          labels:
            severity: critical
        - alert: ThanosQueryHttpRequestQueryRangeErrorRateHigh
          annotations:
            description: Thanos Query {{$labels.job}} is failing to handle {{$value | humanize}}%
              of "query_range" requests.
            runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosqueryhttprequestqueryrangeerrorratehigh
            summary: Thanos Query is failing to handle requests.
          expr: |
            (
              sum by (job) (rate(http_requests_total{code=~"5..", job=~".*thanos-query.*", handler="query_range"}[5m]))
            /
              sum by (job) (rate(http_requests_total{job=~".*thanos-query.*", handler="query_range"}[5m]))
            ) * 100 > 5
          for: 5m
          labels:
            severity: critical
        - alert: ThanosQueryGrpcServerErrorRate
          annotations:
            description: Thanos Query {{$labels.job}} is failing to handle {{$value | humanize}}%
              of requests.
            runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosquerygrpcservererrorrate
            summary: Thanos Query is failing to handle requests.
          expr: |
            (
              sum by (job) (rate(grpc_server_handled_total{grpc_code=~"Unknown|ResourceExhausted|Internal|Unavailable|DataLoss|DeadlineExceeded", job=~".*thanos-query.*"}[5m]))
            /
              sum by (job) (rate(grpc_server_started_total{job=~".*thanos-query.*"}[5m]))
            * 100 > 5
            )
          for: 5m
          labels:
            severity: warning
        - alert: ThanosQueryGrpcClientErrorRate
          annotations:
            description: Thanos Query {{$labels.job}} is failing to send {{$value | humanize}}%
              of requests.
            runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosquerygrpcclienterrorrate
            summary: Thanos Query is failing to send requests.
          expr: |
            (
              sum by (job) (rate(grpc_client_handled_total{grpc_code!="OK", job=~".*thanos-query.*"}[5m]))
            /
              sum by (job) (rate(grpc_client_started_total{job=~".*thanos-query.*"}[5m]))
            ) * 100 > 5
          for: 5m
          labels:
            severity: warning
        - alert: ThanosQueryHighDNSFailures
          annotations:
            description: Thanos Query {{$labels.job}} have {{$value | humanize}}% of failing
              DNS queries for store endpoints.
            runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosqueryhighdnsfailures
            summary: Thanos Query is having high number of DNS failures.
          expr: |
            (
              sum by (job) (rate(thanos_query_store_apis_dns_failures_total{job=~".*thanos-query.*"}[5m]))
            /
              sum by (job) (rate(thanos_query_store_apis_dns_lookups_total{job=~".*thanos-query.*"}[5m]))
            ) * 100 > 1
          for: 15m
          labels:
            severity: warning
        - alert: ThanosQueryInstantLatencyHigh
          annotations:
            description: Thanos Query {{$labels.job}} has a 99th percentile latency of {{$value}}
              seconds for instant queries.
            runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosqueryinstantlatencyhigh
            summary: Thanos Query has high latency for queries.
          expr: |
            (
              histogram_quantile(0.99, sum by (job, le) (rate(http_request_duration_seconds_bucket{job=~".*thanos-query.*", handler="query"}[5m]))) > 40
            and
              sum by (job) (rate(http_request_duration_seconds_bucket{job=~".*thanos-query.*", handler="query"}[5m])) > 0
            )
          for: 10m
          labels:
            severity: critical
        - alert: ThanosQueryRangeLatencyHigh
          annotations:
            description: Thanos Query {{$labels.job}} has a 99th percentile latency of {{$value}}
              seconds for range queries.
            runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosqueryrangelatencyhigh
            summary: Thanos Query has high latency for queries.
          expr: |
            (
              histogram_quantile(0.99, sum by (job, le) (rate(http_request_duration_seconds_bucket{job=~".*thanos-query.*", handler="query_range"}[5m]))) > 90
            and
              sum by (job) (rate(http_request_duration_seconds_count{job=~".*thanos-query.*", handler="query_range"}[5m])) > 0
            )
          for: 10m
          labels:
            severity: critical
